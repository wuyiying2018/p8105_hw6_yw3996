---
title: "Homework 6"
author: "Yiying Wu"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# R packages
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = .8,
  out.width = "90%"
)
```

## 1
### Importing data
```{r,warning=FALSE,message=FALSE}
# import dataset
homicide <- read_csv("homicide-data.csv")
```
### Tidying and wrangling the data
```{r,warning=FALSE}
homicide_clean <- homicide %>%
  mutate(city_state = paste(city, state, sep = ", ")) %>%
  filter(!(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"))) %>%
  filter(victim_race %in% c("White", "Black")) %>%
  mutate(solved = if_else(disposition == "Closed by arrest", 1, 0)) %>%
  mutate(victim_age = as.numeric(victim_age))

# head(homicide_clean)
```
### Fit a logistic regression model for Baltimore, MD
```{r}
baltimore_data <- homicide_clean %>%
                  filter(city_state == "Baltimore, MD")

# Fit logistic regression
model <- glm(solved ~ victim_age + victim_sex + victim_race, data = baltimore_data, family = "binomial")

# Use broom::tidy to obtain estimates and confidence intervals
broom::tidy(model) %>%knitr::kable(digits = 4)
```
Calculate adjusted odds ratios and 95% CI
```{r,warning=FALSE,message=FALSE}
# Calculate adjusted odds ratios 
adjusted_or <- exp(coef(model)["victim_sexMale"])  # For Male vs Female comparison
CI <- confint(model)  # Default confidence interval
CI_adjusted_or <- exp(CI["victim_sexMale", ])

# Displaying the adjusted odds ratio and its confidence interval
adjusted_or
CI_adjusted_or
```

The adjusted odds ratio of 0.426 indicates that in Baltimore, MD, the likelihood of resolving a homicide case involving male victims is 42.6% of that for female victims, after adjusting for additional variables. This suggests a lower probability of solving cases with male victims compared to female ones. The 95% confidence interval, ranging from 0.324 to 0.558, supports this finding and is statistically significant, evidenced by the fact that it does not include 1. 

### Run glm for each city and extract the odds ratio (OR) for male vs. female victims

```{r,warning=FALSE}
# Fit models for each city and extract ORs
city_models <- homicide_clean %>%
               group_by(city_state) %>%
               nest() %>%
               mutate(model = map(data, ~glm(solved ~ victim_age + victim_sex + victim_race, data = .x, family = "binomial")),
                      tidied = map(model, broom::tidy,conf.int = TRUE))

# Unnest the data
city_or <- city_models %>%
           unnest(tidied) %>%
           filter(term == "victim_sexMale") %>%
            mutate(OR = exp(estimate),
                            CI_lower = exp(conf.low),
                            CI_upper = exp(conf.high))%>%
           select(city_state, term, OR, CI_lower, CI_upper)
city_or%>%knitr::kable(digits = 4)
```

### Plotting
```{r}
# Plotting
ggplot(city_or, aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper), width = 0.2) +
  coord_flip() +
  xlab("City") +
  ylab("Adjusted Odds Ratio (Male vs Female Victims)") +
  ggtitle("Adjusted Odds Ratios for Solving Homicides by City")
```

The plot displays the adjusted odds ratios (ORs) for solving homicides by city, comparing male to female victims. It appears that most cities have an OR less than 1, suggesting that homicides with male victims are less likely to be solved than those with female victims when controlling for other factors. This trend is consistent across various cities, indicating a possible widespread pattern. Some cities have notably wider confidence intervals, suggesting less precision in the estimate possibly due to smaller sample sizes or greater variability in the data. The cities are ranked by their estimated ORs, highlighting differences in the likelihood of solving homicides involving male victims across different urban areas. 

## 2
### Download Central Park weather data
```{r,message=FALSE,warning=FALSE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```

### Fitting a simple linear regression model
```{r}
fit0 <- lm(tmax ~ tmin + prcp, data = weather_df)
```

### Bootstrap analysis for $\hat r^2$ and $\log(\hat\beta_1\times \hat\beta_2)$
```{r,warning=FALSE}
set.seed(8105)

# Generating 5000 bootstraps of the dataset
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  data_frame(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

# Generating 5000 bootstrap estimates
bootstrap_results = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin + prcp, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

# Computing log_betas and getting 5000 of those estiamtes
log_betas <-  
  bootstrap_results %>%
  group_by(strap_number) %>%
  summarise(log_betas = log(estimate[2] * estimate[3])) %>%
  select(log_betas, strap_number)

# Generating 5000 bootstrap estimates
bootstrap_results2 <- 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin + prcp, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) 

# Getting 5000 R-Squared estimates
r_squared <- 
  bootstrap_results2 %>%
  select(r.squared, strap_number)
```

### Fitting density plots of two estimates
```{r,warning=FALSE}
log_betas_sd <- 
  log_betas %>%
  summarise(log_betas_sd = sd(as.numeric(log_betas),na.rm = TRUE)) %>%
  pull(log_betas_sd)

log_betas_mean <- 
  log_betas %>% 
  summarise(log_betas_mean = mean(as.numeric(log_betas), na.rm = TRUE)) %>%
  pull(log_betas_mean)

log_betas %>%
  ggplot(aes(x = log_betas)) + geom_density() +
  labs(title = "Distribution of log(Beta1 * Beta2)")
```

The density curve for $\log(\hat\beta_1\times \hat\beta_2)$ is left-skewed with a mean around `r round(log_betas_mean,4)` and a sd around `r round(log_betas_sd,4)`

```{r,warning=FALSE}
r_squared_sd <-
  r_squared %>%
  summarise(r_squared_sd = sd(r.squared)) %>%
  pull(r_squared_sd)

r_squared_mean <-
  r_squared %>%
  summarise(r_squared_mean = mean(r.squared)) %>%
  pull(r_squared_mean)

r_squared %>%
  ggplot(aes(x = r.squared)) + geom_density()+
  labs(title = "Distribution of R-squared")
```

The density curve for $\hat r^2$ is slightly left-skewed with a mean around `r round(r_squared_mean,4)` and a sd around `r round(r_squared_sd,4)`

### 95% CI for $\log(\hat\beta_1\times \hat\beta_2)$
```{r}
CI_result <-
  log_betas %>%
  summarize(ci_lower = quantile(log_betas, 0.025, na.rm = TRUE),
            ci_upper = quantile(log_betas, 0.975, na.rm = TRUE))

CI_result_lower <- CI_result %>% pull(ci_lower)
CI_result_upper <- CI_result %>% pull(ci_upper)
```

95% Confidence Interval of $\log(\hat\beta_1\times \hat\beta_2)$ is between (`r round(CI_result_lower,4)`,`r round(CI_result_upper,4)`)

### 95% CI for $\hat r^2$
```{r}
CI_result2 <-
  r_squared %>%
  summarize(ci_lower = quantile(r.squared, 0.025),
            ci_upper = quantile(r.squared, 0.975)) 

CI_result_lower2 <- CI_result2 %>% pull(ci_lower)
CI_result_upper2 <- CI_result2 %>% pull(ci_upper)
```

95% Confidence Interval of $\hat r^2$ is between (`r round(CI_result_lower2,4)`,`r round(CI_result_upper2,4)`)

## 3
### Importing data
```{r,message=FALSE,warning=FALSE}
birthweight <- read_csv("birthweight.csv")
```
### Tidying and wrangling the data
```{r}
cleaned_birthweight <-
  birthweight %>% 
  janitor::clean_names() %>%
  mutate(across(.cols = c(babysex, frace, malform, mrace), as.factor)) %>%
  mutate(babysex = ifelse(babysex == "1", "male","female"),
         malform = ifelse(malform == "0", "absent","present"),
         frace = recode(frace, "1" = "White", "2" = "Black", "3" = "Asian", 
                        "4" = "Puerto Rican", "8" = "Other", "9" = "Unknown"),
         mrace = recode(mrace, "1" = "White", "2" = "Black", 
                        "3" = "Asian", "4" = "Puerto Rican", "8" = "Other")
         )
```
Changed categorical variables: babysex, frace, malform, and mrace into factors and recoded numerical values of these categorical variables to their associated information.

### Checking Missing Values
```{r}
skimr::skim(cleaned_birthweight)
```

There is no missing data. The dimension of the birthweight data is `r nrow(cleaned_birthweight)` x `r ncol(cleaned_birthweight)`. The `r ncol(cleaned_birthweight)` variables include: `r names(cleaned_birthweight)`.

### Fit the full model
```{r}
full_model <- lm(bwt ~ ., data = cleaned_birthweight)
summary(full_model)
```

The coefficients for babysex, bhead, blength, delwt, gaweeks, mrace, parity, and smoken are significant at the 0.05 level. The NAs for pnumlbw, pnumsga, and wtgain suggest that there are issues with these variables in the model, such as multicollinearity.

### Proposed model
```{r}
model_fit <- lm(bwt ~ babysex + bhead + blength + delwt + gaweeks + mrace + parity + smoken, data = cleaned_birthweight)

summary(model_fit) %>% 
  broom::tidy() %>%
  select(term, estimate, p.value)%>%
  knitr::kable(digits = 4)
```

```{r}
summary(model_fit) %>% 
  broom::glance()%>%
  knitr::kable(digits = 4)
```

Baby's gender, head circumference, length at birth, gestational age in weeks, motherâ€™s race, number of live births prior to this pregnancy, and average number of cigarettes smoked per day during pregnancy explains 71.48% of the variability in birthweight. 

### Model residuals
```{r}
cleaned_birthweight %>%
  modelr::add_predictions(model_fit) %>%
  modelr::add_residuals(model_fit) %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(x = "Fitted Values", y = "Residuals", title = "Residuals vs Fitted Plot for Birthweight Model")
```

